import requests
import io
import re
import os
from docx import Document
from datetime import datetime, timedelta
import json

# –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –¥–ª—è —Ñ–∞–π–ª–∞ –∫—ç—à–∞
CACHE_FILE = os.path.join(os.path.dirname(__file__), "last_docx_url.txt")

weekday_map = {
    0: "–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫",
    1: "–í—Ç–æ—Ä–Ω–∏–∫",
    2: "–°—Ä–µ–¥–∞",
    3: "–ß–µ—Ç–≤–µ—Ä–≥",
    4: "–ü—è—Ç–Ω–∏—Ü–∞",
    5: "–°—É–±–±–æ—Ç–∞",
    6: "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"
}

def normalize_day(day):
    return day.strip().lower().replace("—ë", "–µ") if isinstance(day, str) else ""

def normalize_group(g):
    return re.sub(r"\W+", "", g.strip().lower()) if isinstance(g, str) else ""

def fetch_latest_docx_url(page_url):
    try:
        response = requests.get(page_url)
        response.raise_for_status()
        html = response.text

        match = re.search(r'href="([^"]*Zamena_SAYT\.docx[^"]*)"', html)
        if match:
            return "http://www.bobruisk.belstu.by" + match.group(1)
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å—Å—ã–ª–∫—É –Ω–∞ DOCX.")
            return None
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Å—ã–ª–∫–∏: {e}")
        return None

def get_week_type_from_docx(doc):
    full_text = []
    for para in doc.paragraphs:
        full_text.append(para.text.lower())

    text_content = " ".join(full_text)

    if "–≤–µ—Ä—Ö–Ω—è—è –Ω–µ–¥–µ–ª—è" in text_content:
        return "upper"
    elif "–Ω–∏–∂–Ω—è—è –Ω–µ–¥–µ–ª—è" in text_content:
        return "lower"
    return None

def has_docx_url_changed(new_url, cache_file=CACHE_FILE):
    try:
        with open(cache_file, "r") as f:
            old_url = f.read().strip()
    except FileNotFoundError:
        old_url = ""

    if new_url != old_url:
        with open(cache_file, "w") as f:
            f.write(new_url)
        return True
    return False

def load_docx_from_url(url):
    response = requests.get(url)
    response.raise_for_status()
    return Document(io.BytesIO(response.content))

def get_day_from_table(table):
    for row in table.rows[:2]:
        for cell in row.cells:
            text = cell.text.strip().upper()
            match = re.search(r'(–ü–û–ù–ï–î–ï–õ–¨–ù–ò–ö|–í–¢–û–†–ù–ò–ö|–°–†–ï–î–ê|–ß–ï–¢–í–ï–†–ì|–ü–Ø–¢–ù–ò–¶–ê|–°–£–ë–ë–û–¢–ê|–í–û–°–ö–†–ï–°–ï–ù–¨–ï)', text)
            if match:
                return match.group(1).capitalize()
    return None


def parse_schedule_table(table, target_group, day_label):
    schedule_data = {
        "group": target_group,
        "schedule": []
    }

    current_group = None
    group_found = False

    for row in table.rows:
        cells = [cell.text.strip() for cell in row.cells]

        if not any(cells):
            continue

        if len(cells) == 2 and cells[0] and cells[1]:
            group = cells[0]
            comment = cells[1]
            if normalize_group(group) == normalize_group(target_group):
                group_found = True
                schedule_data["schedule"].append({
                    "day": day_label,
                    "comment": comment
                })
            continue

        if cells[0] and not cells[0].startswith("-"):
            current_group = cells[0]
            group_found = normalize_group(current_group) == normalize_group(target_group)

        if not group_found:
            continue

        try:
            pair_number = cells[1] if len(cells) > 1 else None
            room = cells[2] if len(cells) > 2 else None
            subject_to = cells[3] if len(cells) > 3 else None
            teacher_to = cells[4] if len(cells) > 4 else None
            subject_from = cells[5] if len(cells) > 5 else None
            teacher_from = cells[7] if len(cells) > 6 else None

            schedule_data["schedule"].append({
                "day": day_label,
                "pair": str(pair_number).strip() if pair_number else None,
                "room": room,
                "from": {
                    "subject": subject_from,
                    "teacher": teacher_from
                },
                "to": {
                    "subject": subject_to,
                    "teacher": teacher_to
                }
            })
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏: {e}")
            continue

    return schedule_data

def get_docx_schedule(group_name, page_url="http://www.bobruisk.belstu.by/dnevnoe-otdelenie/raspisanie-zanyatiy-i-zvonkov-zamenyi#gsc.tab=0", doc_updated=False):
    docx_url = fetch_latest_docx_url(page_url)
    if not docx_url:
        return None

    try:
        doc = load_docx_from_url(docx_url)

        full_schedule = {
            "group": group_name,
            "schedule": []
        }

        week_type = get_week_type_from_docx(doc)
        full_schedule["week_type"] = week_type
        print(f"üìå –¢–∏–ø –Ω–µ–¥–µ–ª–∏: {week_type}")

        # –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–Ω–µ–π –∏–∑ –∞–±–∑–∞—Ü–µ–≤
        day_labels = []
        for para in doc.paragraphs:
            text = para.text.strip().upper()
            match = re.search(r'(–ü–û–ù–ï–î–ï–õ–¨–ù–ò–ö|–í–¢–û–†–ù–ò–ö|–°–†–ï–î–ê|–ß–ï–¢–í–ï–†–ì|–ü–Ø–¢–ù–ò–¶–ê|–°–£–ë–ë–û–¢–ê|–í–û–°–ö–†–ï–°–ï–ù–¨–ï)', text)
            if match:
                day_labels.append(match.group(1).capitalize())

        print(f"üìÖ –ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–Ω–∏ –ø–µ—Ä–µ–¥ —Ç–∞–±–ª–∏—Ü–∞–º–∏: {day_labels}")

        # –ü—Ä–∏–≤—è–∑–∫–∞ –¥–Ω–µ–π –∫ —Ç–∞–±–ª–∏—Ü–∞–º
        for i, table in enumerate(doc.tables):
            if i < len(day_labels):
                day_label = day_labels[i]
            else:
                # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü –±–æ–ª—å—à–µ, —á–µ–º –¥–Ω–µ–π ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤
                target_day = datetime.now() + timedelta(days=1)
                if target_day.weekday() == 6: 
                    target_day += timedelta(days=1)
                day_label = weekday_map[target_day.weekday()]
                print(f"‚ö†Ô∏è –î–µ–Ω—å –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {i}, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤: {day_label}")

            result = parse_schedule_table(table, group_name, day_label)
            full_schedule["schedule"].extend(result["schedule"])

        if full_schedule["schedule"]:
            return full_schedule
        else:
            print(f"‚ö†Ô∏è –ì—Ä—É–ø–ø–∞ {group_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ.")
            return full_schedule

    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return None
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ DOCX: {e}")
        return None


def get_available_replacement_days(doc_schedule):
    days_with_replacements = set()

    for item in doc_schedule.get("schedule", []):
        if "to" in item and item.get("day"):
            days_with_replacements.add(item["day"].strip())

    return sorted(days_with_replacements)

if __name__ == '__main__':
    MY_GROUP = "–†–°02-24"
    DOC_PAGE_URL = "http://www.bobruisk.belstu.by/dnevnoe-otdelenie/raspisanie-zanyatiy-i-zvonkov-zamenyi"
    
    DOCX_URL = fetch_latest_docx_url(DOC_PAGE_URL)
    doc_updated = has_docx_url_changed(DOCX_URL) 
    
    schedule = get_docx_schedule(MY_GROUP, DOC_PAGE_URL, doc_updated) 

    if schedule:
        print("‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∑–∞–º–µ–Ω:")
        print(json.dumps(schedule, indent=4, ensure_ascii=False))

        available_days = get_available_replacement_days(schedule)
        print("\nüìå –î–Ω–∏, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∞–π–¥–µ–Ω—ã –∑–∞–º–µ–Ω—ã:")
        print(available_days)
